{
 "metadata": {
  "name": "",
  "signature": "sha256:11b61ada117bdd270d124c3c5331342e0fbfb7c806c2fc307210da8abf0f3b55"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import math\n",
      "\n",
      "# A hand implementation of a Naive Bayes classifier\n",
      "# y = argmax_k of the prob of class Ck times the product of p (x[i] | C[k]) for i from 1 to n\n",
      "# meaning that since each point uses the same denominator we can effectively just consider the numerator (the prior * likelihood)\n",
      "\n",
      "#for now we assume one class to predict\n",
      "#let's use pandas\n",
      "\n",
      "model = 'Gaussian'\n",
      "\n",
      "def calc_sample_mean(input_data):\n",
      "    mean = np.mean(input_data)\n",
      "    return mean\n",
      "\n",
      "def calc_sample_variance(input_data):\n",
      "    '''\n",
      "       For the set of data\n",
      "       calculate mean\n",
      "       for each number\n",
      "           subtract mean, sqr result\n",
      "        calculate average\n",
      "       return avg\n",
      "    '''\n",
      "    mean_ = calc_sample_mean(input_data)\n",
      "    array = np.array(input_data)\n",
      "    for val in array:\n",
      "        val -= mean_\n",
      "        val = val ** 2\n",
      "    return sum(array) / len(array)\n",
      "\n",
      "class NaiveBayes(object):\n",
      "    \n",
      "    def __init__(self, filename, class_column_index):\n",
      "        self.data = pd.read_csv(filename)\n",
      "        self.class_col_index = class_column_index\n",
      "        self.feature_columns = [x for x in self.data.columns if x != class_column_index]\n",
      "        self.prior = {}\n",
      "        for x in self.data[self.class_col_index].unique():\n",
      "            self.prior[x] = 0.0\n",
      "        self.calc_priors()\n",
      "        \n",
      "        \n",
      "    def predict(self, instances):\n",
      "        print instances\n",
      "        max_keys = []\n",
      "        for idx in instances.index:\n",
      "            instance = instances.ix[idx]\n",
      "            print \"instance: \", instance\n",
      "\n",
      "            posterior_ = self.posterior(instance)\n",
      "            print posterior_\n",
      "            max_val = 0\n",
      "            max_key = ''\n",
      "            for key in posterior_.keys():\n",
      "                if posterior_[key] > max_val:\n",
      "                    max_val = posterior_[key]\n",
      "                    max_key = key\n",
      "            max_keys.append(max_key)\n",
      "        \n",
      "        \n",
      "    def likelihood(self, x, feature_class_column_tup):\n",
      "        '''\n",
      "            For the Gaussian model, assumes continuous valued traits\n",
      "            if model == 'Gaussian'\n",
      "                calculate sample variance\n",
      "                calculate sample mean\n",
      "                estimate prob\n",
      "        '''\n",
      "        class_subset_ = self.data[self.data[feature_class_column_tup[1]] == feature_class_column_tup[2]]\n",
      "        feature_class_subset_ = class_subset_[feature_class_column_tup[0]]\n",
      "        \n",
      "        if model == 'Gaussian':\n",
      "            var = calc_sample_variance(feature_class_subset_)\n",
      "            mean = calc_sample_mean(feature_class_subset_)\n",
      "            left_ = 1/math.sqrt(2*math.pi*var)\n",
      "            right_ = math.exp((-(float(x)-mean) ** 2) / (2*var))\n",
      "            return left_ * right_\n",
      "        \n",
      "        \n",
      "\n",
      "    def posterior(self, instance):\n",
      "        #go through each unique value for the class, and then generate the likelihood value for each feature coniditioned on that class value\n",
      "        '''\n",
      "        likelihood_prod = 1.0\n",
      "        for value in class_values\n",
      "            for each feature column:\n",
      "                likelihood_prod *= likelihood(feature column, value)\n",
      "            update posterior for value according to prior * likelihood_prod\n",
      "        '''\n",
      "        likelihood_prod = 1.0\n",
      "        class_col = self.data[self.class_col_index]\n",
      "        class_values = class_col.unique()\n",
      "        posterior_ = {}\n",
      "        for value in class_values:\n",
      "            print \"class value: \", value\n",
      "            for feature_column_index in self.feature_columns:\n",
      "                likelihood_prod *= self.likelihood(instance[feature_column_index], (feature_column_index, self.class_col_index, value))\n",
      "            try:\n",
      "                print \"prior: \", self.prior[value], \" likeli: \", likelihood_prod\n",
      "                posterior_[value] = self.prior[value] * likelihood_prod\n",
      "            except:\n",
      "                print \"prior: \", self.prior[value], \" likeli: \", likelihood_prod\n",
      "                posterior_[value] = self.prior[value] * likelihood_prod\n",
      "        return posterior_\n",
      "\n",
      "    def score(data):\n",
      "        #Take a 10% holdout set, get a prediction accuracy. Not stratified\n",
      "        permutated_index = np.random.permutation(data.index)\n",
      "        training_split = (9/10) * len(permutated_index)\n",
      "        training_set = data[permutated_index[:training_split]]\n",
      "        validation_set = data[permutated_index[training_split:]]\n",
      "        \n",
      "        self.calc_priors(training_set)\n",
      "        predictions = self.predict(validation_set)\n",
      "        pred = 0\n",
      "        accuracy = 0\n",
      "        for val_idx in validation_set.index:\n",
      "            val_instance = validation_set.ix[val_idx]\n",
      "            if val_instance[self.class_col_index] == predictions[pred]:\n",
      "                accuracy += 1\n",
      "            pred += 1\n",
      "        \n",
      "        res = float(accuracy) / len(validation_set.index)\n",
      "        return res\n",
      "    \n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "    def fit(self):\n",
      "        cv_score = []\n",
      "        k = 10\n",
      "        for i in xrange(k):\n",
      "            #get training(and validation) data\n",
      "            #get testing data\n",
      "            \n",
      "            permutated_index = np.random.permutation(self.data.index)\n",
      "            training_split = (9/10) * len(permutated_index)\n",
      "            print training_split, len(data.index)\n",
      "            training_data = self.data[permutated_index[:training_split]]\n",
      "            testing_data = self.data[permutated_index[training_split:]]\n",
      "            \n",
      "            cv_score.append(score(training_data))\n",
      "            \n",
      "            \n",
      "            #hold out validation data\n",
      "            #fit training data\n",
      "            #record error from testing on validation\n",
      "            \n",
      "        return float(sum(cv_score)) / 10.0\n",
      "        \n",
      "    #TODO: smarter training set selection\n",
      "    def calc_priors(self, training_data=None):\n",
      "        # go through each unique value for the class, and update/initialize priors\n",
      "\n",
      "        '''\n",
      "        for each unique class value\n",
      "            self.posterior[value] = number of occurences of value / total number of instances\n",
      "        '''\n",
      "        if not training_data:\n",
      "            class_col = self.data[self.class_col_index]\n",
      "        else:\n",
      "            class_col = training_data[self.class_col_index]\n",
      "            \n",
      "        class_col_uniques = class_col.unique()\n",
      "        class_col_total = len(class_col)\n",
      "        for val in class_col_uniques:\n",
      "            num_val = len(class_col[class_col == val])\n",
      "            self.prior[val] = float(num_val) / float(class_col_total)\n",
      "            \n",
      "        return\n",
      "    \n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "\n",
      "def gen_random_data(num):\n",
      "    f = open('sample_data.csv', 'w+')\n",
      "    f.write('age,height,weight,cancer\\n')\n",
      "    i = 0\n",
      "    while i < num:\n",
      "        age = random.randrange(10, 70, 1)\n",
      "        height = random.randrange(70, 210, 1)\n",
      "        weight = random.randrange(130, 225, 1)\n",
      "        cancer = random.randint(0,1)\n",
      "        if cancer == 1:\n",
      "            cancer_str = 'yes'\n",
      "        else:\n",
      "            cancer_str = 'no'\n",
      "        f.write(str(age) + ',' + str(height) + ',' + str(weight) + ',' + str(cancer_str) + '\\n')\n",
      "        i += 1\n",
      "    f.close()\n",
      "gen_random_data(1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "clf = NaiveBayes('sample_data.csv', 'cancer')\n",
      "input_data = pd.DataFrame(columns=['age', 'height', 'weight'])\n",
      "input_data.loc[0] = [15, 155, 150]\n",
      "input_data.loc[1] = [20, 165, 160]\n",
      "print input_data\n",
      "print clf.fit()\n",
      "#clf.predict(input_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   age  height  weight\n",
        "0   15     155     150\n",
        "1   20     165     160\n",
        "0"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "global name 'data' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-8-4ce8f2d0e776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m165\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#clf.predict(input_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-7-48d567d483b3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mpermutated_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mtraining_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutated_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mprint\u001b[0m \u001b[0mtraining_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpermutated_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtraining_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mtesting_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpermutated_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_split\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: global name 'data' is not defined"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "likelihood() takes exactly 2 arguments (3 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-44-0c9e8611e547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m155\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-42-6ef0a0940dee>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, instances)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mposterior_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mmax_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mmax_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-42-6ef0a0940dee>\u001b[0m in \u001b[0;36mposterior\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature_column_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mlikelihood_prod\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeature_column_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_col_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mposterior_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlikelihood_prod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: likelihood() takes exactly 2 arguments (3 given)"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}